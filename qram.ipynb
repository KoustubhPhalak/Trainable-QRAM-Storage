{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from sklearn.utils import shuffle\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pennylane as qml\n",
    "# from livelossplot import PlotLosses\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datetime import datetime\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits().data\n",
    "classes = load_digits().target\n",
    "filter = np.where((classes == 0 )|(classes == 1))\n",
    "data, classes = data[filter], classes[filter]\n",
    "data, classes = shuffle(data, classes)\n",
    "data, classes = data[:45], classes[:45]\n",
    "# print(data.shape, classes.shape)\n",
    "x_aux = data\n",
    "y = classes\n",
    "x_main = list(range(len(data)))\n",
    "for i in range(len(x_main)):\n",
    "    x_main[i] = np.binary_repr(x_main[i], width=9)\n",
    "    x_main[i] = [int(char) for char in x_main[i]]\n",
    "\n",
    "# x_main = (x_main-np.mean(x_main))/np.std(x_main)\n",
    "# x_aux = (x_aux -np.mean(x_aux))/np.std(x_aux)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# DEFINE AUX PQC STRUCTURE AND DECLARE TORCHLAYER FOR IT\n",
    "wires_aux_pqc = 6\n",
    "layers_aux = 3\n",
    "dev = qml.device(\"default.qubit\", wires=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed AUX PQC + Trainable QRAM PQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wires_aux_pqc = 6\n",
    "# layers_aux = 3\n",
    "# dev = qml.device(\"default.qubit\", wires=9)\n",
    "\n",
    "# rand_params = np.random.uniform(high=2 * np.pi, size=(layers_aux, 20))\n",
    "\n",
    "# @qml.qnode(dev, interface='torch')\n",
    "# def aux_pqc(inputs):\n",
    "#     qml.AmplitudeEmbedding(features=inputs,normalize=True,wires=range(wires_aux_pqc))\n",
    "#     seed = 42\n",
    "#     qml.RandomLayers(weights=rand_params, wires=range(wires_aux_pqc),seed=seed)\n",
    "#     return qml.probs(wires=range(wires_aux_pqc))\n",
    "\n",
    "# wires_qcnn = 9\n",
    "# layers_qcnn = 3\n",
    "# @qml.qnode(dev, interface='torch')\n",
    "# def qcnn(inputs, params, weights):\n",
    "#     qml.AngleEmbedding(features=inputs, wires=range(wires_qcnn), rotation='Y')\n",
    "#     # qml.BasisEmbedding(features=inputs, wires=range(wires_qcnn))\n",
    "#     for l in range(layers_qcnn):\n",
    "#         cnt = 0\n",
    "#         # shape = qml.StronglyEntanglingLayers.shape(n_layers=layers_qcnn, n_wires=wires_qcnn)\n",
    "#         # weights = np.random.random(size=shape)\n",
    "#         for i in range(wires_qcnn - 1):\n",
    "#             qml.RY(params[l*36+cnt],wires=i)\n",
    "#             qml.RY(params[l*36+cnt+1],wires=i+1)\n",
    "#             qml.CNOT(wires=[i,i+1])\n",
    "#             qml.CRZ(params[l*36+cnt+2], wires=[i,i+1])\n",
    "#             qml.PauliX(wires=i+1)\n",
    "#             qml.CRX(params[l*36+cnt+3],wires=[i,i+1])\n",
    "#             cnt = cnt + 4\n",
    "#         for i in [wires_qcnn - 1]:\n",
    "#             qml.RY(params[l*36+cnt],wires=i)\n",
    "#             qml.RY(params[l*36+cnt+1],wires=i-(wires_qcnn - 1))\n",
    "#             qml.CNOT(wires=[i,i-(wires_qcnn - 1)])\n",
    "#             qml.CRZ(params[l*36+cnt+2], wires=[i,i-(wires_qcnn - 1)])\n",
    "#             qml.PauliX(wires=i-(wires_qcnn - 1))\n",
    "#             qml.CRX(params[l*36+cnt+3],wires=[i,i-(wires_qcnn - 1)])\n",
    "#             cnt = cnt + 4\n",
    "#     qml.StronglyEntanglingLayers(weights=weights, wires=range(wires_qcnn))\n",
    "#     return qml.probs(wires=[0,1,2,6,7,8])\n",
    "\n",
    "# weights_qcnn = {\"params\":layers_qcnn*36, \"weights\":(layers_qcnn,wires_qcnn,layers_qcnn)}\n",
    "\n",
    "# qcnn_main = qml.qnn.TorchLayer(qcnn, weights_qcnn, init_method=torch.nn.init.normal_)\n",
    "\n",
    "# loss_function = torch.nn.MSELoss()\n",
    "# # optimizer = torch.optim.SGD(qcnn_main.parameters(),lr=0.001,momentum=0.9,nesterov=True)\n",
    "# optimizer = torch.optim.Adam(qcnn_main.parameters(),lr=0.01)\n",
    "\n",
    "# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# BATCH_SIZE = 20\n",
    "\n",
    "# x_aux = torch.tensor(x_aux).to(DEVICE)\n",
    "# y = torch.tensor(y,dtype=torch.double).to(DEVICE)\n",
    "# x_main = torch.tensor(x_main, dtype=torch.float64).to(DEVICE)\n",
    "\n",
    "# epochs = 20\n",
    "# for epoch in range(epochs):\n",
    "#     print(\"******EPOCH #\" + str(epoch) + \" START ******\")\n",
    "#     epoch_loss = torch.tensor([0], dtype=torch.float64).to(DEVICE)\n",
    "#     running_acc = 0\n",
    "#     for i in range(x_aux.shape[0]//BATCH_SIZE):\n",
    "#         bs_counter = 0\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = torch.tensor([0], dtype=torch.float64, requires_grad=True).to(DEVICE)\n",
    "#         while bs_counter < BATCH_SIZE: \n",
    "#             # print(x_main[i*BATCH_SIZE+bs_counter])\n",
    "#             ground_truth = aux_pqc(x_aux[i*BATCH_SIZE+bs_counter])\n",
    "#             pred = qcnn_main(x_main[i*BATCH_SIZE+bs_counter])\n",
    "#             # print(pred.tolist())\n",
    "#             temp_loss = torch.tensor([0], dtype=torch.float64, requires_grad=True).to(DEVICE)\n",
    "#             a = []\n",
    "#             for j in range(len(pred)):\n",
    "#                 temp_loss = temp_loss + loss_function(pred[j], ground_truth[j])\n",
    "#                 a.append(torch.abs(pred[j]-ground_truth[j]).item())\n",
    "#             loss = loss + temp_loss\n",
    "#             epoch_loss = epoch_loss + loss\n",
    "#             # loss = loss + loss_function(pred, y_train[i*BATCH_SIZE+bs_counter])\n",
    "#             # print(temp_loss.item())\n",
    "#             if temp_loss.item() < 0.05:\n",
    "#                 running_acc = running_acc + 1\n",
    "#             bs_counter = bs_counter + 1\n",
    "#         loss = loss/BATCH_SIZE\n",
    "#         # loss.requires_grad = True\n",
    "#         loss.backward()\n",
    "#         # for param in qcnn_main.parameters():\n",
    "#         #     print(param.grad)\n",
    "#         optimizer.step()\n",
    "#         if i % 5 == 0 and i != 0:\n",
    "#             # print(pred, y_train[i*BATCH_SIZE+bs_counter])\n",
    "#             # for j in range(pred.shape[0]):\n",
    "#             #     if j == 0:\n",
    "#             #         # print(pred[j].item(), ground_truth[j].item())\n",
    "#             #         print(pred)\n",
    "#             print(\"Running Accuracy: \" + str(running_acc/((i+1)*BATCH_SIZE)*100) + \"%\")\n",
    "#     print(\"EPOCH LOSS:\" + str(epoch_loss.item()))\n",
    "#     print(\"******EPOCH #\" + str(epoch) + \" END ******\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainable Aux PQC + Trainable QRAM PQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******EPOCH #0 START ******\n",
      "EPOCH LOSS:6.656999490819594\n",
      "******EPOCH #0 END ******\n",
      "******EPOCH #1 START ******\n",
      "EPOCH LOSS:5.600795601888476\n",
      "******EPOCH #1 END ******\n",
      "******EPOCH #2 START ******\n",
      "EPOCH LOSS:4.880166569267084\n",
      "******EPOCH #2 END ******\n",
      "******EPOCH #3 START ******\n",
      "EPOCH LOSS:4.3881093049327\n",
      "******EPOCH #3 END ******\n",
      "******EPOCH #4 START ******\n",
      "EPOCH LOSS:4.04250681705732\n",
      "******EPOCH #4 END ******\n",
      "****\n",
      "\n",
      "\n",
      "\n",
      "****\n",
      "******EPOCH #0 START ******\n",
      "EPOCH LOSS:3.7795817735565844\n",
      "******EPOCH #0 END ******\n",
      "******EPOCH #1 START ******\n",
      "EPOCH LOSS:3.5746346251073726\n",
      "******EPOCH #1 END ******\n",
      "******EPOCH #2 START ******\n",
      "EPOCH LOSS:3.423576469004699\n",
      "******EPOCH #2 END ******\n",
      "******EPOCH #3 START ******\n",
      "EPOCH LOSS:3.313613430591445\n",
      "******EPOCH #3 END ******\n",
      "******EPOCH #4 START ******\n",
      "EPOCH LOSS:3.224138983846711\n",
      "******EPOCH #4 END ******\n"
     ]
    }
   ],
   "source": [
    "@qml.qnode(dev, interface='torch')\n",
    "def aux_pqc(inputs, params):\n",
    "    qml.AmplitudeEmbedding(features=inputs,normalize=True,wires=range(wires_aux_pqc))\n",
    "    seed = 42\n",
    "    qml.RandomLayers(weights=params, wires=range(wires_aux_pqc),seed=seed)\n",
    "    return qml.probs(wires=range(wires_aux_pqc))\n",
    "\n",
    "weights_aux = {'params':(layers_aux, 20)}\n",
    "\n",
    "qcnn_aux = qml.qnn.TorchLayer(aux_pqc, weights_aux, init_method=torch.nn.init.normal_)\n",
    "\n",
    "# DEFINE MAIN QRAM PQC STRUCTURE AND DECLARE TORCHLAYER FOR IT\n",
    "wires_qcnn = 9\n",
    "layers_qcnn = 3\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def qcnn(inputs, params, weights):\n",
    "    qml.AngleEmbedding(features=inputs, wires=range(wires_qcnn), rotation='Y')\n",
    "    # qml.BasisEmbedding(features=inputs, wires=range(wires_qcnn))\n",
    "    for l in range(layers_qcnn):\n",
    "        cnt = 0\n",
    "        #shape = qml.StronglyEntanglingLayers.shape(n_layers=layers_qcnn, n_wires=wires_qcnn)\n",
    "        #weights = np.random.random(size=shape)\n",
    "        for i in range(wires_qcnn - 1):\n",
    "            qml.RY(params[l*36+cnt],wires=i)\n",
    "            qml.RY(params[l*36+cnt+1],wires=i+1)\n",
    "            qml.CNOT(wires=[i,i+1])\n",
    "            qml.CRZ(params[l*36+cnt+2], wires=[i,i+1])\n",
    "            qml.PauliX(wires=i+1)\n",
    "            qml.CRX(params[l*36+cnt+3],wires=[i,i+1])\n",
    "            cnt = cnt + 4\n",
    "        for i in [wires_qcnn - 1]:\n",
    "            qml.RY(params[l*36+cnt],wires=i)\n",
    "            qml.RY(params[l*36+cnt+1],wires=i-(wires_qcnn - 1))\n",
    "            qml.CNOT(wires=[i,i-(wires_qcnn - 1)])\n",
    "            qml.CRZ(params[l*36+cnt+2], wires=[i,i-(wires_qcnn - 1)])\n",
    "            qml.PauliX(wires=i-(wires_qcnn - 1))\n",
    "            qml.CRX(params[l*36+cnt+3],wires=[i,i-(wires_qcnn - 1)])\n",
    "            cnt = cnt + 4\n",
    "    qml.StronglyEntanglingLayers(weights=weights, wires=range(wires_qcnn))\n",
    "    return qml.probs(wires=[0,1,2,6,7,8])\n",
    "\n",
    "weights_qcnn = {\"params\":layers_qcnn*36, \"weights\":(layers_qcnn,wires_qcnn,layers_qcnn)}\n",
    "\n",
    "qcnn_main = qml.qnn.TorchLayer(qcnn, weights_qcnn, init_method=torch.nn.init.normal_)\n",
    "\n",
    "# DEFINE OVERALL QRAM CLASS CONSISTING OF BOTH AUX PQC AND MAIN PQC\n",
    "class QRAM(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.qcnn_aux = torch.nn.Sequential(qcnn_aux)\n",
    "        self.qcnn_main = torch.nn.Sequential(qcnn_main)\n",
    "    \n",
    "    def forward(self,x_aux,x_main):\n",
    "        ground_truth = self.qcnn_aux(x_aux)\n",
    "        pred = self.qcnn_main(x_main)\n",
    "        return ground_truth, pred\n",
    "\n",
    "qram = QRAM().to(DEVICE).float()\n",
    "\n",
    "loss_function = torch.nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(qcnn_main.parameters(),lr=0.001,momentum=0.9,nesterov=True)\n",
    "optimizer = torch.optim.Adam(qram.parameters(),lr=0.01)\n",
    "\n",
    "x_aux = torch.tensor(x_aux).to(DEVICE)\n",
    "y = torch.tensor(y,dtype=torch.double).to(DEVICE)\n",
    "x_main = torch.tensor(x_main, dtype=torch.float64).to(DEVICE)\n",
    "\n",
    "# TRAIN AUX PQC AND MAIN PQC TOGETHER\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(\"******EPOCH #\" + str(epoch) + \" START ******\")\n",
    "    epoch_loss = torch.tensor([0], dtype=torch.float64).to(DEVICE)\n",
    "    running_acc = 0\n",
    "    for i in range(x_aux.shape[0]//BATCH_SIZE):\n",
    "        bs_counter = 0\n",
    "        optimizer.zero_grad()\n",
    "        loss = torch.tensor([0], dtype=torch.float64, requires_grad=True).to(DEVICE)\n",
    "        while bs_counter < BATCH_SIZE: \n",
    "            # print(x_main[i*BATCH_SIZE+bs_counter])\n",
    "            # ground_truth = aux_pqc(x_aux[i*BATCH_SIZE+bs_counter])\n",
    "            # pred = qcnn_main(x_main[i*BATCH_SIZE+bs_counter])\n",
    "            ground_truth, pred  = qram(x_aux[i*BATCH_SIZE+bs_counter],x_main[i*BATCH_SIZE+bs_counter])\n",
    "            # print(pred.tolist())\n",
    "            temp_loss = torch.tensor([0], dtype=torch.float64, requires_grad=True).to(DEVICE)\n",
    "            a = []\n",
    "            for j in range(len(pred)):\n",
    "                temp_loss = temp_loss + loss_function(pred[j], ground_truth[j])\n",
    "                a.append(torch.abs(pred[j]-ground_truth[j]).item())\n",
    "            loss = loss + temp_loss\n",
    "            epoch_loss = epoch_loss + loss\n",
    "            # loss = loss + loss_function(pred, y_train[i*BATCH_SIZE+bs_counter])\n",
    "            # print(temp_loss.item())\n",
    "            if temp_loss.item() < 0.05:\n",
    "                running_acc = running_acc + 1\n",
    "            bs_counter = bs_counter + 1\n",
    "        loss = loss/BATCH_SIZE\n",
    "        # loss.requires_grad = True\n",
    "        loss.backward()\n",
    "        # for param in qcnn_main.parameters():\n",
    "        #     print(param.grad)\n",
    "        optimizer.step()\n",
    "        if i % 5 == 0 and i != 0:\n",
    "            # print(pred, y_train[i*BATCH_SIZE+bs_counter])\n",
    "            # for j in range(pred.shape[0]):\n",
    "            #     print(pred[j].item(), ground_truth[j].item())\n",
    "            print(\"Running Accuracy: \" + str(running_acc/((i+1)*BATCH_SIZE)*100) + \"%\")\n",
    "    print(\"EPOCH LOSS:\" + str(epoch_loss.item()))\n",
    "    print(\"******EPOCH #\" + str(epoch) + \" END ******\")\n",
    "\n",
    "print(\"****\")\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"****\")\n",
    "\n",
    "# TRAIN ONLY MAIN PQC AND KEEP TRAINED AUX PQC PARAMETERS FIXED\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(\"******EPOCH #\" + str(epoch) + \" START ******\")\n",
    "    epoch_loss = torch.tensor([0], dtype=torch.float64).to(DEVICE)\n",
    "    running_acc = 0\n",
    "    for i in range(x_aux.shape[0]//BATCH_SIZE):\n",
    "        bs_counter = 0\n",
    "        optimizer.zero_grad()\n",
    "        loss = torch.tensor([0], dtype=torch.float64, requires_grad=True).to(DEVICE)\n",
    "        while bs_counter < BATCH_SIZE: \n",
    "            # print(x_main[i*BATCH_SIZE+bs_counter])\n",
    "            # ground_truth = aux_pqc(x_aux[i*BATCH_SIZE+bs_counter])\n",
    "            # pred = qcnn_main(x_main[i*BATCH_SIZE+bs_counter])\n",
    "            ground_truth, pred  = qram(x_aux[i*BATCH_SIZE+bs_counter],x_main[i*BATCH_SIZE+bs_counter])\n",
    "            # print(pred.tolist())\n",
    "            temp_loss = torch.tensor([0], dtype=torch.float64, requires_grad=True).to(DEVICE)\n",
    "            a = []\n",
    "            for j in range(len(pred)):\n",
    "                temp_loss = temp_loss + loss_function(pred[j], ground_truth[j])\n",
    "                a.append(torch.abs(pred[j]-ground_truth[j]).item())\n",
    "            loss = loss + temp_loss\n",
    "            epoch_loss = epoch_loss + loss\n",
    "            # loss = loss + loss_function(pred, y_train[i*BATCH_SIZE+bs_counter])\n",
    "            # print(temp_loss.item())\n",
    "            if temp_loss.item() < 0.05:\n",
    "                running_acc = running_acc + 1\n",
    "            bs_counter = bs_counter + 1\n",
    "        loss = loss/BATCH_SIZE\n",
    "        # loss.requires_grad = True\n",
    "        loss.backward()\n",
    "        for param in qcnn_main.parameters():\n",
    "            if param.shape == (layers_aux, 20):\n",
    "                param.grad = torch.zeros((layers_aux, 20), dtype=torch.float64)\n",
    "        optimizer.step()\n",
    "        if i % 5 == 0 and i != 0:\n",
    "            # print(pred, y_train[i*BATCH_SIZE+bs_counter])\n",
    "            # for j in range(pred.shape[0]):\n",
    "            #     print(pred[j].item(), ground_truth[j].item())\n",
    "            print(\"Running Accuracy: \" + str(running_acc/((i+1)*BATCH_SIZE)*100) + \"%\")\n",
    "    print(\"EPOCH LOSS:\" + str(epoch_loss.item()))\n",
    "    print(\"******EPOCH #\" + str(epoch) + \" END ******\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******EPOCH #0 START ******\n",
      "-0.008706259537270333 0.49564687023136483 1.0\n",
      "-0.0017319088647679837 0.499134045567616 1.0\n",
      "0.0003663020606930467 0.5001831510303465 0.0\n",
      "0.03452505061899336 0.5172625253094967 0.0\n",
      "0.015803400280263225 0.5079017001401316 1.0\n",
      "0.06571744635800303 0.5328587231790015 1.0\n",
      "0.03620575896898515 0.5181028794844926 1.0\n",
      "-0.07197567770962554 0.46401216114518723 1.0\n",
      "-0.04063101298229416 0.4796844935088529 0.0\n",
      "-0.028380417380190037 0.485809791309905 0.0\n",
      "-0.02849727857588802 0.485751360712056 1.0\n",
      "-0.008192719284353833 0.4959036403578231 0.0\n",
      "-0.013550169057151784 0.4932249154714241 0.0\n",
      "0.029528104533305677 0.5147640522666528 0.0\n",
      "0.007430806364427833 0.503715403182214 1.0\n",
      "-0.023412539585336845 0.4882937302073316 1.0\n",
      "-0.03882659053255366 0.48058670473372317 0.0\n",
      "-0.019185290657989573 0.4904073546710052 1.0\n",
      "-0.03624074458824211 0.48187962770587894 0.0\n",
      "-0.005030204285070894 0.4974848978574645 1.0\n",
      "0.012395346018350906 0.5061976730091755 1.0\n",
      "-0.029076462247055346 0.4854617688764723 0.0\n",
      "-0.03469635777107799 0.48265182111446103 0.0\n",
      "-0.031224421943226943 0.48438778902838653 0.0\n",
      "-0.051765903883915276 0.47411704805804233 1.0\n",
      "-0.0566059630602907 0.4716970184698547 0.0\n",
      "-0.07440982547992603 0.462795087260037 1.0\n",
      "-0.01712785519656901 0.4914360724017155 0.0\n",
      "0.0032958450744453582 0.5016479225372227 1.0\n",
      "-0.039850394456934835 0.4800748027715326 1.0\n",
      "-0.03197327142181189 0.48401336428909403 0.0\n",
      "-0.00402673411258514 0.49798663294370743 0.0\n",
      "-0.0565274248501193 0.47173628757494035 1.0\n",
      "-0.0067899539225643735 0.4966050230387178 1.0\n",
      "-0.055239981993400356 0.4723800090032998 1.0\n",
      "0.01031124333984329 0.5051556216699217 1.0\n",
      "-0.00010822809796751098 0.49994588595101624 1.0\n",
      "0.004650659809456559 0.5023253299047283 0.0\n",
      "-0.017200980476356764 0.4913995097618216 1.0\n",
      "-0.01803548625833873 0.49098225687083064 1.0\n",
      "Running Accuracy: 50.0%\n",
      "EPOCH LOSS:104.9415941524322\n",
      "******EPOCH #0 END ******\n",
      "******EPOCH #1 START ******\n",
      "0.005604735287818574 0.5028023676439093 1.0\n",
      "-0.02253052504052666 0.48873473747973667 1.0\n",
      "-0.03007997658469863 0.4849600117076507 0.0\n",
      "0.03303735781716888 0.5165186789085845 0.0\n",
      "-0.03206352209919083 0.4839682389504046 1.0\n",
      "-0.02032281327507024 0.4898385933624649 1.0\n",
      "-0.047007302622930014 0.47649634868853497 1.0\n",
      "0.04169048986978041 0.5208452449348902 1.0\n",
      "-6.571960258217047e-06 0.4999967140198709 0.0\n",
      "-0.013352907613862097 0.49332354619306895 0.0\n",
      "-0.029069898761223123 0.48546505061938844 1.0\n"
     ]
    }
   ],
   "source": [
    "# AUGMENT QNN CLASSIFIER TO THE QRAM AND TRAIN THE QNN CLASSIFIER BY KEEPING TRAINED QRAM PARAMETERS FIXED\n",
    "layers_classifier = 10\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def quantum_ram_classifier(inputs, params, weights, params2):\n",
    "    qml.AngleEmbedding(features=inputs, wires=range(wires_qcnn), rotation='Y')\n",
    "    # QRAM STRUCTURE\n",
    "    for l in range(layers_qcnn):\n",
    "        cnt = 0\n",
    "        for i in range(wires_qcnn - 1):\n",
    "            qml.RY(params[l*36+cnt],wires=i)\n",
    "            qml.RY(params[l*36+cnt+1],wires=i+1)\n",
    "            qml.CNOT(wires=[i,i+1])\n",
    "            qml.CRZ(params[l*36+cnt+2], wires=[i,i+1])\n",
    "            qml.PauliX(wires=i+1)\n",
    "            qml.CRX(params[l*36+cnt+3],wires=[i,i+1])\n",
    "            cnt = cnt + 4\n",
    "        for i in [wires_qcnn - 1]:\n",
    "            qml.RY(params[l*36+cnt],wires=i)\n",
    "            qml.RY(params[l*36+cnt+1],wires=i-(wires_qcnn - 1))\n",
    "            qml.CNOT(wires=[i,i-(wires_qcnn - 1)])\n",
    "            qml.CRZ(params[l*36+cnt+2], wires=[i,i-(wires_qcnn - 1)])\n",
    "            qml.PauliX(wires=i-(wires_qcnn - 1))\n",
    "            qml.CRX(params[l*36+cnt+3],wires=[i,i-(wires_qcnn - 1)])\n",
    "            cnt = cnt + 4\n",
    "    qml.StronglyEntanglingLayers(weights=weights, wires=range(wires_qcnn))\n",
    "    # QNN CLASSIFIER STRUCTURE\n",
    "    for l in range(layers_classifier):\n",
    "        cnt = 0\n",
    "        for i in range(wires_qcnn - 1):\n",
    "            qml.RY(params2[l*36+cnt],wires=i)\n",
    "            qml.RY(params2[l*36+cnt+1],wires=i+1)\n",
    "            qml.CNOT(wires=[i,i+1])\n",
    "            qml.CRZ(params2[l*36+cnt+2], wires=[i,i+1])\n",
    "            qml.PauliX(wires=i+1)\n",
    "            qml.CRX(params2[l*36+cnt+3],wires=[i,i+1])\n",
    "            cnt = cnt + 4\n",
    "        for i in [wires_qcnn - 1]:\n",
    "            qml.RY(params2[l*36+cnt],wires=i)\n",
    "            qml.RY(params2[l*36+cnt+1],wires=i-(wires_qcnn - 1))\n",
    "            qml.CNOT(wires=[i,i-(wires_qcnn - 1)])\n",
    "            qml.CRZ(params2[l*36+cnt+2], wires=[i,i-(wires_qcnn - 1)])\n",
    "            qml.PauliX(wires=i-(wires_qcnn - 1))\n",
    "            qml.CRX(params2[l*36+cnt+3],wires=[i,i-(wires_qcnn - 1)])\n",
    "            cnt = cnt + 4\n",
    "    return qml.expval(qml.PauliZ(0)) \n",
    "\n",
    "weights_qram_classifier = {\"params\":layers_qcnn*36, \"weights\":(layers_qcnn,wires_qcnn,layers_qcnn), \"params2\":layers_classifier*36}\n",
    "\n",
    "qram_classifier = qml.qnn.TorchLayer(quantum_ram_classifier, weights_qram_classifier, init_method=torch.nn.init.uniform_)\n",
    "\n",
    "optimizer_classifier = torch.optim.Adam(qram_classifier.parameters(),lr=0.1)\n",
    "\n",
    "trained_qram_params = list(qcnn_main.parameters())\n",
    "# print(trained_qram_params[0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    cnt = 0\n",
    "    for param in qram_classifier.parameters():\n",
    "        if cnt < 2:\n",
    "            param = trained_qram_params[cnt].data\n",
    "            param.requires_grad = False\n",
    "        # print(param)\n",
    "        cnt = cnt + 1\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    print(\"******EPOCH #\" + str(epoch) + \" START ******\")\n",
    "    epoch_loss = torch.tensor([0], dtype=torch.float64).to(DEVICE)\n",
    "    running_acc = 0\n",
    "    for i in range(x_aux.shape[0]//BATCH_SIZE):\n",
    "        bs_counter = 0\n",
    "        optimizer_classifier.zero_grad()\n",
    "        loss = torch.tensor([0], dtype=torch.float64, requires_grad=True).to(DEVICE)\n",
    "        while bs_counter < BATCH_SIZE: \n",
    "            out = (qram_classifier(x_main[i*BATCH_SIZE+bs_counter])+1.0)/2\n",
    "            # print(qram_classifier(x_main[i*BATCH_SIZE+bs_counter]).item(), qram_classifier(x_main[i*BATCH_SIZE+bs_counter]).item()+1.0,(qram_classifier(x_main[i*BATCH_SIZE+bs_counter]).item()+1.0)/2, y[i*BATCH_SIZE+bs_counter].item())\n",
    "            # print(out < torch.tensor(0, dtype=torch.float64))\n",
    "            # if out < torch.tensor(0, dtype=torch.float64):\n",
    "            #     out = torch.tensor(0,dtype=torch.float64, requires_grad=True).to(DEVICE)\n",
    "            # else:\n",
    "            #     out = torch.tensor(1, dtype=torch.float64, requires_grad=True).to(DEVICE)\n",
    "            # temp_loss = torch.tensor([0], dtype=torch.float64, requires_grad=True).to(DEVICE)\n",
    "            # temp_loss = temp_loss + loss_function(out, y[i*BATCH_SIZE+bs_counter])\n",
    "            loss = loss + loss_function((qram_classifier(x_main[i*BATCH_SIZE+bs_counter])+1.0)/2, y[i*BATCH_SIZE+bs_counter])\n",
    "            # print(out.item(), y[i*BATCH_SIZE+bs_counter].item())\n",
    "            epoch_loss = epoch_loss + loss\n",
    "            if loss_function((qram_classifier(x_main[i*BATCH_SIZE+bs_counter])+1.0)/2, y[i*BATCH_SIZE+bs_counter]).item() < 0.25:\n",
    "                running_acc = running_acc + 1\n",
    "            bs_counter = bs_counter + 1\n",
    "            print(qram_classifier(x_main[i*BATCH_SIZE+bs_counter]).item(), (qram_classifier(x_main[i*BATCH_SIZE+bs_counter]).item()+1.0)/2, y[i*BATCH_SIZE+bs_counter].item())\n",
    "        loss = loss/BATCH_SIZE\n",
    "        loss.backward()\n",
    "        cnt = 0\n",
    "        for param in qram_classifier.parameters():\n",
    "            # if cnt < 2:\n",
    "            #     param.grad = torch.zeros(param.shape, dtype=param.grad.dtype)\n",
    "            # cnt = cnt + 1\n",
    "            # print(param.grad)\n",
    "            pass\n",
    "        optimizer_classifier.step()\n",
    "        if i % 1 == 0 and i != 0:\n",
    "            print(\"Running Accuracy: \" + str(running_acc/((i+1)*BATCH_SIZE)*100) + \"%\")\n",
    "    print(\"EPOCH LOSS:\" + str(epoch_loss.item()))\n",
    "    print(\"******EPOCH #\" + str(epoch) + \" END ******\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Without QRAM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******EPOCH #0 START ******\n",
      "0.09492901525512754 0.5474645076275637 1.0\n",
      "0.027854178241309813 0.5139270891206549 1.0\n",
      "0.009757902163612386 0.5048789510818061 0.0\n",
      "0.0028918774307795103 0.5014459387153898 0.0\n",
      "0.10274883478540742 0.5513744173927038 1.0\n",
      "0.05796552047064518 0.5289827602353225 1.0\n",
      "0.08626791100543141 0.5431339555027157 1.0\n",
      "0.07702714086063922 0.5385135704303197 1.0\n",
      "0.051613861397529714 0.5258069306987648 0.0\n",
      "0.0469964987726581 0.523498249386329 0.0\n",
      "0.1113704432026954 0.5556852216013477 1.0\n",
      "0.05407236791994008 0.52703618395997 0.0\n",
      "-0.001306173994141624 0.4993469130029292 0.0\n",
      "0.000916351747035582 0.5004581758735178 0.0\n",
      "0.07284224611853951 0.5364211230592697 1.0\n",
      "0.06613776701352347 0.5330688835067617 1.0\n",
      "0.00024714416878113266 0.5001235720843906 0.0\n",
      "0.07603103745517137 0.5380155187275857 1.0\n",
      "0.018153264206618835 0.5090766321033094 0.0\n",
      "0.015394370428004123 0.5076971852140021 1.0\n",
      "0.1169095037963318 0.558454751898166 1.0\n",
      "0.000543807843747024 0.5002719039218735 0.0\n",
      "-0.002388138320730371 0.4988059308396348 0.0\n",
      "0.04575912909363877 0.5228795645468194 0.0\n",
      "0.044363672708253477 0.5221818363541267 1.0\n",
      "0.04722035693729687 0.5236101784686484 0.0\n",
      "0.10934275283073691 0.5546713764153685 1.0\n",
      "0.021854718148054286 0.5109273590740271 0.0\n",
      "0.11553633047948736 0.5577681652397437 1.0\n",
      "0.1083921963710589 0.5541960981855294 1.0\n",
      "0.0195275223498389 0.5097637611749195 0.0\n",
      "0.01879597247024345 0.5093979862351217 0.0\n",
      "0.08794344799945597 0.5439717239997279 1.0\n",
      "0.12807341238509373 0.5640367061925469 1.0\n",
      "0.10503728381177757 0.5525186419058887 1.0\n",
      "0.10171146077550602 0.550855730387753 1.0\n",
      "0.10581848132928551 0.5529092406646428 1.0\n",
      "0.02407952550271697 0.5120397627513584 0.0\n",
      "0.07977071795745516 0.5398853589787276 1.0\n",
      "0.0657962045056022 0.5328981022528011 1.0\n",
      "Running Accuracy: 62.5%\n",
      "EPOCH LOSS:97.25888164909748\n",
      "******EPOCH #0 END ******\n",
      "******EPOCH #1 START ******\n",
      "0.14446019536668658 0.5722300976833433 1.0\n",
      "0.07557679676525908 0.5377883983826295 1.0\n",
      "-0.0040382234804419714 0.49798088825977904 0.0\n",
      "-0.017103598989529623 0.4914482005052352 0.0\n",
      "0.1681810253554602 0.58409051267773 1.0\n",
      "0.10783903563432473 0.5539195178171623 1.0\n",
      "0.1590510767058233 0.5795255383529117 1.0\n",
      "0.12247738109646089 0.5612386905482305 1.0\n",
      "0.04437519610631979 0.5221875980531598 0.0\n",
      "0.03054012219891772 0.5152700610994588 0.0\n",
      "0.17185702592056384 0.5859285129602819 1.0\n",
      "0.051912334986857545 0.5259561674934288 0.0\n",
      "-0.012334289161853362 0.4938328554190733 0.0\n",
      "-0.024394287730659325 0.48780285613467034 0.0\n",
      "0.13699064380265996 0.56849532190133 1.0\n",
      "0.12745012528274346 0.5637250626413717 1.0\n",
      "-0.0159138818865473 0.49204305905672635 0.0\n",
      "0.14620209955430485 0.5731010497771525 1.0\n",
      "0.011628131111946216 0.5058140655559731 0.0\n",
      "0.05551135354056935 0.5277556767702847 1.0\n",
      "0.17915740841733502 0.5895787042086675 1.0\n",
      "-0.009202938231180846 0.49539853088440955 0.0\n",
      "-0.019156992969359077 0.49042150351532043 0.0\n",
      "0.028142895998340522 0.5140714479991703 0.0\n",
      "0.08210346855613015 0.5410517342780651 1.0\n",
      "0.03756116656105701 0.5187805832805286 0.0\n",
      "0.15851237188696315 0.5792561859434816 1.0\n",
      "0.0044918638706329395 0.5022459319353165 0.0\n",
      "0.1720571056020665 0.5860285528010333 1.0\n",
      "0.173483672946401 0.5867418364732004 1.0\n",
      "0.0012732885207070166 0.5006366442603535 0.0\n",
      "0.0075573606583672626 0.5037786803291836 0.0\n",
      "0.13670098049372048 0.5683504902468602 1.0\n",
      "0.17173511793020269 0.5858675589651013 1.0\n",
      "0.17017212562262168 0.5850860628113108 1.0\n",
      "0.10645003498996719 0.5532250174949835 1.0\n",
      "0.1621602088244109 0.5810801044122055 1.0\n",
      "0.011559113899888895 0.5057795569499445 0.0\n",
      "0.13916779737849927 0.5695838986892496 1.0\n",
      "0.10470799747784865 0.5523539987389243 1.0\n",
      "Running Accuracy: 75.0%\n",
      "EPOCH LOSS:90.5460260577159\n",
      "******EPOCH #1 END ******\n",
      "******EPOCH #2 START ******\n",
      "0.18210319059733665 0.5910515952986684 1.0\n",
      "0.11335550030564906 0.5566777501528245 1.0\n",
      "-0.020377619675791492 0.4898111901621043 0.0\n",
      "-0.0368887865422452 0.48155560672887743 0.0\n",
      "0.22116367901150752 0.6105818395057537 1.0\n",
      "0.14637998013052833 0.5731899900652642 1.0\n",
      "0.2196637609211073 0.6098318804605536 1.0\n",
      "0.15529491071892232 0.5776474553594612 1.0\n",
      "0.03303353287363053 0.5165167664368153 0.0\n",
      "0.014333929287337455 0.5071669646436687 0.0\n",
      "0.21859114421777193 0.609295572108886 1.0\n",
      "0.0423748183814629 0.5211874091907315 0.0\n",
      "-0.022590408382825167 0.4887047958085874 0.0\n",
      "-0.045193224311433855 0.47740338784428304 0.0\n",
      "0.18919705037147883 0.5945985251857394 1.0\n",
      "0.17816157476365468 0.5890807873818273 1.0\n",
      "-0.030560831913466424 0.48471958404326676 0.0\n",
      "0.20048443373741648 0.6002422168687083 1.0\n",
      "0.0035107134047043798 0.5017553567023522 0.0\n",
      "0.09155316667671232 0.5457765833383561 1.0\n",
      "0.22731613866264067 0.6136580693313203 1.0\n",
      "-0.023314319160776753 0.4883428404196116 0.0\n",
      "-0.03963211482903117 0.4801839425854844 0.0\n",
      "0.005320877471465479 0.5026604387357327 0.0\n",
      "0.11585032617090629 0.5579251630854531 1.0\n",
      "0.020974425320055 0.5104872126600275 0.0\n",
      "0.19459917123020726 0.5972995856151037 1.0\n",
      "-0.014411411201714242 0.4927942943991429 0.0\n",
      "0.2147178305427937 0.6073589152713968 1.0\n",
      "0.22601348005339128 0.6130067400266956 1.0\n",
      "-0.019954979045795296 0.4900225104771023 0.0\n",
      "-0.007536604858943308 0.4962316975705283 0.0\n",
      "0.17164819448459095 0.5858240972422954 1.0\n",
      "0.20032710547248073 0.6001635527362403 1.0\n",
      "0.2212013205047697 0.6106006602523848 1.0\n",
      "0.10529129978578777 0.5526456498928939 1.0\n",
      "0.2044312033413353 0.6022156016706677 1.0\n",
      "-0.005361272657237626 0.4973193636713812 0.0\n",
      "0.18604988972767622 0.593024944863838 1.0\n",
      "0.13826141521674717 0.5691307076083736 1.0\n",
      "Running Accuracy: 85.0%\n",
      "EPOCH LOSS:85.01851200846194\n",
      "******EPOCH #2 END ******\n",
      "******EPOCH #3 START ******\n",
      "0.2067436911173941 0.603371845558697 1.0\n",
      "0.1409079384156019 0.570453969207801 1.0\n",
      "-0.03999416592376692 0.48000291703811654 0.0\n",
      "-0.05711249284599429 0.47144375357700286 0.0\n",
      "0.25970693330148376 0.6298534666507418 1.0\n",
      "0.1734986463430787 0.5867493231715394 1.0\n",
      "0.26531039233061593 0.632655196165308 1.0\n",
      "0.17473351840632884 0.5873667592031644 1.0\n",
      "0.018267253626845503 0.5091336268134228 0.0\n",
      "-0.0029065304737533326 0.49854673476312333 0.0\n",
      "0.25079722922514147 0.6253986146125707 1.0\n",
      "0.027364010265405136 0.5136820051327026 0.0\n",
      "-0.03396862415948598 0.483015687920257 0.0\n",
      "-0.06346809496143713 0.46826595251928144 0.0\n",
      "0.2276085630445805 0.6138042815222903 1.0\n",
      "0.21676105563489967 0.6083805278174499 1.0\n",
      "-0.045720361203689 0.47713981939815553 0.0\n",
      "0.2362937961393899 0.6181468980696949 1.0\n",
      "-0.007768234786229511 0.4961158826068852 0.0\n",
      "0.1219742064767857 0.5609871032383928 1.0\n",
      "0.2641178798153674 0.6320589399076837 1.0\n",
      "-0.03974915629538306 0.48012542185230844 0.0\n",
      "-0.05979629183951363 0.4701018540802432 0.0\n",
      "-0.019685405553935553 0.49015729722303225 0.0\n",
      "0.14499366099436256 0.5724968304971813 1.0\n",
      "0.002553565606695729 0.5012767828033479 0.0\n",
      "0.2201482915096244 0.6100741457548122 1.0\n",
      "-0.033389188087597055 0.4833054059562015 0.0\n",
      "0.24603645711202293 0.6230182285560115 1.0\n",
      "0.26758271623760493 0.6337913581188025 1.0\n",
      "-0.04104787632441392 0.479476061837793 0.0\n",
      "-0.02399185266291548 0.48800407366854226 0.0\n",
      "0.1951744653466475 0.5975872326733238 1.0\n",
      "0.21811420886082433 0.6090571044304122 1.0\n",
      "0.26041780745746534 0.6302089037287326 1.0\n",
      "0.0988326779624174 0.5494163389812087 1.0\n",
      "0.23451979310167548 0.6172598965508378 1.0\n",
      "-0.02332895653186251 0.48833552173406874 0.0\n",
      "0.22270667807585076 0.6113533390379253 1.0\n",
      "0.1662218258486221 0.583110912924311 1.0\n",
      "Running Accuracy: 92.5%\n",
      "EPOCH LOSS:80.63480000617406\n",
      "******EPOCH #3 END ******\n",
      "******EPOCH #4 START ******\n",
      "0.22255603343134278 0.6112780167156714 1.0\n",
      "0.16184931585401763 0.5809246579270089 1.0\n",
      "-0.06116185547545416 0.4694190722622729 0.0\n",
      "-0.07705422936391193 0.46147288531804403 0.0\n",
      "0.2894582035561073 0.6447291017780536 1.0\n",
      "0.19374766257387133 0.5968738312869357 1.0\n",
      "0.30087580954006893 0.6504379047700345 1.0\n",
      "0.1849925365270706 0.5924962682635353 1.0\n",
      "0.002151687785816425 0.5010758438929082 0.0\n",
      "-0.021044798946557308 0.48947760052672135 0.0\n",
      "0.27414985029247985 0.63707492514624 1.0\n",
      "0.011594428903415888 0.505797214451708 0.0\n",
      "-0.04575708047621241 0.4771214597618938 0.0\n",
      "-0.07933725868339819 0.4603313706583009 0.0\n",
      "0.2572149114964448 0.6286074557482224 1.0\n",
      "0.2469715347991116 0.6234857673995557 1.0\n",
      "-0.06127705026640051 0.46936147486679974 0.0\n",
      "0.25942642316089326 0.6297132115804467 1.0\n",
      "-0.020041963862934664 0.48997901806853267 0.0\n",
      "0.1468298134319479 0.573414906715974 1.0\n",
      "0.2937162658374686 0.6468581329187343 1.0\n",
      "-0.05736338711136979 0.4713183064443151 0.0\n",
      "-0.07840436066403744 0.4607978196679813 0.0\n",
      "-0.04569402730733657 0.47715298634633174 0.0\n",
      "0.16877831657064823 0.5843891582853241 1.0\n",
      "-0.01537275621390155 0.4923136218930492 0.0\n",
      "0.23884645177804664 0.6194232258890233 1.0\n",
      "-0.05261341003351977 0.4736932949832401 0.0\n",
      "0.27014750894134665 0.6350737544706733 1.0\n",
      "0.30164015481669243 0.6508200774083462 1.0\n",
      "-0.061167010414935385 0.46941649479253234 0.0\n",
      "-0.04113699446819835 0.47943150276590085 0.0\n",
      "0.21158177938423328 0.6057908896921167 1.0\n",
      "0.22993775989377008 0.6149688799468851 1.0\n",
      "0.2920855589747697 0.6460427794873849 1.0\n",
      "0.08860565679205212 0.5443028283960261 1.0\n",
      "0.25711333858778995 0.628556669293895 1.0\n",
      "-0.04144807475051848 0.47927596262474076 0.0\n",
      "0.2527243451957725 0.6263621725978863 1.0\n",
      "0.1889784360825133 0.5944892180412567 1.0\n",
      "Running Accuracy: 95.0%\n",
      "EPOCH LOSS:77.05496066287886\n",
      "******EPOCH #4 END ******\n",
      "******EPOCH #5 START ******\n",
      "0.2331558879149167 0.6165779439574584 1.0\n",
      "0.17864544470334487 0.5893227223516724 1.0\n",
      "-0.08436924503996851 0.4578153774800158 0.0\n",
      "-0.09795446338367403 0.451022768308163 0.0\n",
      "0.3146329475444489 0.6573164737722245 1.0\n",
      "0.21007627556717046 0.6050381377835852 1.0\n",
      "0.3303335018009733 0.6651667509004866 1.0\n",
      "0.1897584303055554 0.5948792151527778 1.0\n",
      "-0.015693050898486105 0.492153474550757 0.0\n",
      "-0.04151468230390404 0.47924265884804795 0.0\n",
      "0.29301099031198663 0.6465054951559933 1.0\n",
      "-0.0031994016059370134 0.4984002991970315 0.0\n",
      "-0.05870455562800786 0.47064772218599604 0.0\n",
      "-0.09489214819954367 0.45255392590022814 0.0\n",
      "0.28182285803320406 0.640911429016602 1.0\n",
      "0.27190521240760174 0.6359526062038009 1.0\n",
      "-0.07856146865423874 0.46071926567288063 0.0\n",
      "0.27607671538425205 0.638038357692126 1.0\n",
      "-0.032714759375495284 0.48364262031225236 0.0\n",
      "0.16579057179729872 0.5828952858986494 1.0\n",
      "0.3191798932577632 0.6595899466288816 1.0\n",
      "-0.0766452593774638 0.4616773703112681 0.0\n",
      "-0.09621137620545617 0.4518943118972719 0.0\n",
      "-0.0728753484941771 0.46356232575291145 0.0\n",
      "0.18707338226197145 0.5935366911309857 1.0\n",
      "-0.03301979776174169 0.48349010111912916 0.0\n",
      "0.2538583504362678 0.6269291752181338 1.0\n",
      "-0.07318694261316805 0.463406528693416 0.0\n",
      "0.29030402991319093 0.6451520149565955 1.0\n",
      "0.33099427222677563 0.6654971361133878 1.0\n",
      "-0.08124919524161545 0.4593754023791923 0.0\n",
      "-0.059656067920578426 0.4701719660397108 0.0\n",
      "0.22433379326932862 0.6121668966346643 1.0\n",
      "0.23913920375528447 0.6195696018776422 1.0\n",
      "0.31955775269307596 0.659778876346538 1.0\n",
      "0.07524208975560964 0.5376210448778048 1.0\n",
      "0.2758892240695566 0.6379446120347783 1.0\n",
      "-0.060082608024943585 0.4699586959875282 0.0\n",
      "0.27871309455500914 0.6393565472775046 1.0\n",
      "0.2068985317559982 0.6034492658779991 1.0\n",
      "Running Accuracy: 100.0%\n",
      "EPOCH LOSS:73.9222335929169\n",
      "******EPOCH #5 END ******\n",
      "******EPOCH #6 START ******\n",
      "0.24095815982031948 0.6204790799101597 1.0\n",
      "0.1922933915313374 0.5961466957656687 1.0\n",
      "-0.1101378130020092 0.4449310934989954 0.0\n",
      "-0.12075841494036954 0.43962079252981523 0.0\n",
      "0.337412022359711 0.6687060111798555 1.0\n",
      "0.22396124497106762 0.6119806224855338 1.0\n",
      "0.35616445795536744 0.6780822289776838 1.0\n",
      "0.19169881331697047 0.5958494066584852 1.0\n",
      "-0.03548743694772111 0.4822562815261394 0.0\n",
      "-0.0652339641409736 0.4673830179295132 0.0\n",
      "0.3097391029475024 0.6548695514737513 1.0\n",
      "-0.01654032203704997 0.49172983898147504 0.0\n",
      "-0.07353651226515923 0.4632317438674204 0.0\n",
      "-0.11197130464328753 0.44401434767835624 0.0\n",
      "0.30370231357698113 0.6518511567884906 1.0\n",
      "0.2935373795280244 0.6467686897640121 1.0\n",
      "-0.0985617151648403 0.4507191424175798 0.0\n",
      "0.2907291532536481 0.6453645766268241 1.0\n",
      "-0.04574015645639107 0.47712992177180447 0.0\n",
      "0.1792566412856909 0.5896283206428454 1.0\n",
      "0.3424025303478751 0.6712012651739375 1.0\n",
      "-0.0975662671649612 0.4512168664175194 0.0\n",
      "-0.11348264761114935 0.4432586761944253 0.0\n",
      "-0.1006994014703062 0.4496502992648469 0.0\n",
      "0.20062336668761804 0.600311683343809 1.0\n",
      "-0.05048152281713103 0.4747592385914345 0.0\n",
      "0.26773496211503656 0.6338674810575182 1.0\n",
      "-0.09527967023795675 0.4523601648810216 0.0\n",
      "0.30868778841061884 0.6543438942053095 1.0\n",
      "0.3576308570735204 0.6788154285367602 1.0\n",
      "-0.10162730188585067 0.44918634905707466 0.0\n",
      "-0.07943153380503104 0.46028423309748445 0.0\n",
      "0.2362052367415461 0.6181026183707731 1.0\n",
      "0.24796216949386485 0.6239810847469325 1.0\n",
      "0.3451002650615087 0.6725501325307544 1.0\n",
      "0.05979999283718712 0.5298999964185935 1.0\n",
      "0.2932294376162266 0.6466147188081133 1.0\n",
      "-0.07882610759369896 0.46058694620315055 0.0\n",
      "0.3024717909747524 0.6512358954873763 1.0\n",
      "0.22074139676688098 0.6103706983834405 1.0\n",
      "Running Accuracy: 100.0%\n",
      "EPOCH LOSS:71.02397880624832\n",
      "******EPOCH #6 END ******\n",
      "******EPOCH #7 START ******\n",
      "0.24770968109448765 0.6238548405472438 1.0\n",
      "0.20310271444453165 0.6015513572222658 1.0\n",
      "-0.1374984818834814 0.43125075905825927 0.0\n",
      "-0.14488791338369067 0.42755604330815467 0.0\n",
      "0.3586732517880776 0.6793366258940388 1.0\n",
      "0.2362419310107715 0.6181209655053858 1.0\n",
      "0.3797067675490725 0.6898533837745362 1.0\n",
      "0.19284396769235024 0.5964219838461751 1.0\n",
      "-0.05642708842455446 0.47178645578772277 0.0\n",
      "-0.0915489437720971 0.45422552811395145 0.0\n",
      "0.3253890195107116 0.6626945097553558 1.0\n",
      "-0.027998951158467456 0.48600052442076624 0.0\n",
      "-0.08995626183209049 0.45502186908395476 0.0\n",
      "-0.1307246365715954 0.4346376817142023 0.0\n",
      "0.3241240104706486 0.6620620052353243 1.0\n",
      "0.3130326932247064 0.6565163466123531 1.0\n",
      "-0.12077317583748026 0.43961341208125987 0.0\n",
      "0.306074981485223 0.6530374907426115 1.0\n",
      "-0.05861951165678614 0.47069024417160693 0.0\n",
      "0.18829969213659725 0.5941498460682986 1.0\n",
      "0.364071906717901 0.6820359533589505 1.0\n",
      "-0.11924821217272641 0.4403758939136368 0.0\n",
      "-0.12987759919309405 0.435061200403453 0.0\n",
      "-0.1280444390566129 0.43597778047169355 0.0\n",
      "0.21035555289258734 0.6051777764462937 1.0\n",
      "-0.06740378264982438 0.4662981086750878 0.0\n",
      "0.2819788125406117 0.6409894062703059 1.0\n",
      "-0.11806871078335468 0.44096564460832266 0.0\n",
      "0.32627684353413466 0.6631384217670673 1.0\n",
      "0.38249259570488164 0.6912462978524408 1.0\n",
      "-0.12170434154560605 0.439147829227197 0.0\n",
      "-0.09948669570053315 0.4502566521497334 0.0\n",
      "0.24905698205914928 0.6245284910295746 1.0\n",
      "0.25765282589058436 0.6288264129452922 1.0\n",
      "0.3697929973920064 0.6848964986960032 1.0\n",
      "0.04404633647801737 0.5220231682390086 1.0\n",
      "0.31031265058306934 0.6551563252915347 1.0\n",
      "-0.09648612691113556 0.4517569365444322 0.0\n",
      "0.32472781241157367 0.6623639062057869 1.0\n",
      "0.23125327922344563 0.6156266396117228 1.0\n",
      "Running Accuracy: 100.0%\n",
      "EPOCH LOSS:68.29500071312495\n",
      "******EPOCH #7 END ******\n",
      "******EPOCH #8 START ******\n",
      "0.2542868622747361 0.627143431137368 1.0\n",
      "0.21100022648693917 0.6055001132434696 1.0\n",
      "-0.1648580285723043 0.4175709857138479 0.0\n",
      "-0.1692247096361134 0.41538764518194327 0.0\n",
      "0.3783392147358872 0.6891696073679436 1.0\n",
      "0.24704176020253654 0.6235208801012683 1.0\n",
      "0.40143759804200085 0.7007187990210004 1.0\n",
      "0.19453156209874012 0.59726578104937 1.0\n",
      "-0.07763424683345027 0.46118287658327484 0.0\n",
      "-0.11908694918340479 0.4404565254082976 0.0\n",
      "0.33991765873664925 0.6699588293683246 1.0\n",
      "-0.03753688754739487 0.48123155622630254 0.0\n",
      "-0.10722253110584146 0.44638873444707927 0.0\n",
      "-0.15032423738829231 0.42483788130585387 0.0\n",
      "0.343290653386272 0.671645326693136 1.0\n",
      "0.3307156790868198 0.6653578395434099 1.0\n",
      "-0.1440273208835992 0.4279863395582004 0.0\n",
      "0.32309137647521113 0.6615456882376056 1.0\n",
      "-0.07090212995019124 0.46454893502490435 0.0\n",
      "0.19402005100302622 0.5970100255015132 1.0\n",
      "0.3840307902175161 0.6920153951087581 1.0\n",
      "-0.14074689510658045 0.4296265524467098 0.0\n",
      "-0.14533642729778595 0.427331786351107 0.0\n",
      "-0.15414926491484243 0.4229253675425788 0.0\n",
      "0.2169352435288356 0.6084676217644178 1.0\n",
      "-0.08374113264259231 0.45812943367870385 0.0\n",
      "0.2968525445162011 0.6484262722581006 1.0\n",
      "-0.14073222441729227 0.42963388779135386 0.0\n",
      "0.3429617903880339 0.671480895194017 1.0\n",
      "0.40569481964099613 0.7028474098204981 1.0\n",
      "-0.14090364369277597 0.429548178153612 0.0\n",
      "-0.11909469041239495 0.4404526547938025 0.0\n",
      "0.2634155971674145 0.6317077985837072 1.0\n",
      "0.2683525406131429 0.6341762703065714 1.0\n",
      "0.39374672294238466 0.6968733614711924 1.0\n",
      "0.02972028843602792 0.514860144218014 1.0\n",
      "0.32704762177054825 0.6635238108852741 1.0\n",
      "-0.11214661878589754 0.44392669060705126 0.0\n",
      "0.3452067355687275 0.6726033677843637 1.0\n",
      "0.23884844492411217 0.6194242224620561 1.0\n",
      "Running Accuracy: 100.0%\n",
      "EPOCH LOSS:65.74104535968912\n",
      "******EPOCH #8 END ******\n",
      "******EPOCH #9 START ******\n",
      "0.2606682117308577 0.6303341058654288 1.0\n",
      "0.21625417484663834 0.6081270874233191 1.0\n",
      "-0.19096267156137525 0.4045186642193124 0.0\n",
      "-0.1929894309329056 0.40350528453354717 0.0\n",
      "0.3960879336807268 0.6980439668403634 1.0\n",
      "0.2561070352688256 0.6280535176344129 1.0\n",
      "0.42163739782815723 0.7108186989140786 1.0\n",
      "0.19725309967498672 0.5986265498374934 1.0\n",
      "-0.09865008988418561 0.4506749550579072 0.0\n",
      "-0.1466349610371066 0.4266825194814467 0.0\n",
      "0.35282111127521065 0.6764105556376053 1.0\n",
      "-0.045670991588813825 0.4771645042055931 0.0\n",
      "-0.12470379614743987 0.43764810192628006 0.0\n",
      "-0.16990214639802548 0.41504892680098726 0.0\n",
      "0.36090444057604987 0.680452220288025 1.0\n",
      "0.34665979482206416 0.6733298974110321 1.0\n",
      "-0.16731712500307172 0.41634143749846414 0.0\n",
      "0.3414738305873188 0.6707369152936594 1.0\n",
      "-0.08262122595712063 0.4586893870214397 0.0\n",
      "0.19726640677032192 0.5986332033851609 1.0\n",
      "0.40215185091228955 0.7010759254561447 1.0\n",
      "-0.16137961017291635 0.4193101949135418 0.0\n",
      "-0.16011149817634518 0.4199442509118274 0.0\n",
      "-0.17876117493086185 0.4106194125345691 0.0\n",
      "0.22091810307373838 0.6104590515368692 1.0\n",
      "-0.09967188184526765 0.4501640590773662 0.0\n",
      "0.31191602006207386 0.6559580100310369 1.0\n",
      "-0.16280369643986375 0.4185981517800681 0.0\n",
      "0.3583421682386418 0.6791710841193209 1.0\n",
      "0.42742194523217836 0.7137109726160892 1.0\n",
      "-0.15896793211718718 0.4205160339414064 0.0\n",
      "-0.13806508066905643 0.4309674596654718 0.0\n",
      "0.2787315448615594 0.6393657724307797 1.0\n",
      "0.2794050424993183 0.6397025212496592 1.0\n",
      "0.4169551553670089 0.7084775776835044 1.0\n",
      "0.01786124486458862 0.5089306224322943 1.0\n",
      "0.34250939590917606 0.671254697954588 1.0\n",
      "-0.12574409988396046 0.43712795005801974 0.0\n",
      "0.3635572261409369 0.6817786130704684 1.0\n",
      "0.24392756182955372 0.6219637809147769 1.0\n",
      "Running Accuracy: 100.0%\n",
      "EPOCH LOSS:63.37649118582077\n",
      "******EPOCH #9 END ******\n",
      "******EPOCH #10 START ******\n",
      "0.2663161191763829 0.6331580595881915 1.0\n",
      "0.21989293674682592 0.6099464683734129 1.0\n",
      "-0.21519913870939789 0.39240043064530106 0.0\n",
      "-0.21581529695288193 0.39209235152355904 0.0\n",
      "0.41209729645671234 0.7060486482283561 1.0\n",
      "0.26341389807503 0.631706949037515 1.0\n",
      "0.4409506732133718 0.7204753366066858 1.0\n",
      "0.20072840534026193 0.600364202670131 1.0\n",
      "-0.11937017931627114 0.44031491034186443 0.0\n",
      "-0.17335130710612817 0.41332434644693594 0.0\n",
      "0.36391041246540295 0.6819552062327014 1.0\n",
      "-0.053164372340740285 0.4734178138296299 0.0\n",
      "-0.1418119612730569 0.4290940193634716 0.0\n",
      "-0.18873063017654162 0.40563468491172916 0.0\n",
      "0.37700530938413257 0.6885026546920663 1.0\n",
      "0.3613416322658006 0.6806708161329003 1.0\n",
      "-0.1899481147977357 0.4050259426011321 0.0\n",
      "0.3603956105477338 0.6801978052738669 1.0\n",
      "-0.09419891494233124 0.4529005425288344 0.0\n",
      "0.19879329934654177 0.5993966496732709 1.0\n",
      "0.41872164516761123 0.7093608225838056 1.0\n",
      "-0.1809773855180551 0.40951130724097246 0.0\n",
      "-0.174526475086954 0.412736762456523 0.0\n",
      "-0.20208132823579578 0.3989593358821021 0.0\n",
      "0.2230300912494479 0.6115150456247239 1.0\n",
      "-0.11539716871395467 0.44230141564302267 0.0\n",
      "0.32660813535292044 0.6633040676764602 1.0\n",
      "-0.18420434714310785 0.4078978264284461 0.0\n",
      "0.37231359729002145 0.6861567986450108 1.0\n",
      "0.44824171132867974 0.7241208556643399 1.0\n",
      "-0.17591572314485837 0.4120421384275708 0.0\n",
      "-0.1565417118535118 0.42172914407324413 0.0\n",
      "0.2940655340601749 0.6470327670300875 1.0\n",
      "0.2897760752778673 0.6448880376389337 1.0\n",
      "0.43964664903249684 0.7198233245162484 1.0\n",
      "0.00850990877900576 0.5042549543895029 1.0\n",
      "0.3555526158437382 0.677776307921869 1.0\n",
      "-0.1381590528569855 0.43092047357150726 0.0\n",
      "0.3799388077022601 0.68996940385113 1.0\n",
      "0.24721142318720302 0.6236057115936016 1.0\n",
      "Running Accuracy: 100.0%\n",
      "EPOCH LOSS:61.19392111058699\n",
      "******EPOCH #10 END ******\n",
      "******EPOCH #11 START ******\n",
      "0.27070858774615636 0.6353542938730782 1.0\n",
      "0.2232355793038402 0.6116177896519202 1.0\n",
      "-0.2375846162605098 0.3812076918697451 0.0\n",
      "-0.23763503516162987 0.38118248241918506 0.0\n",
      "0.4269229672711917 0.7134614836355959 1.0\n",
      "0.26931071420700053 0.6346553571035003 1.0\n",
      "0.46009123987947387 0.7300456199397369 1.0\n",
      "0.20426049256901369 0.6021302462845068 1.0\n",
      "-0.1399947530487362 0.4300026234756319 0.0\n",
      "-0.1988416578519291 0.40057917107403546 0.0\n",
      "0.37345620474670793 0.686728102373354 1.0\n",
      "-0.06079053041615645 0.4696047347919218 0.0\n",
      "-0.15806047294739567 0.42096976352630217 0.0\n",
      "-0.20625956422244873 0.39687021788877563 0.0\n",
      "0.39204122378959116 0.6960206118947956 1.0\n",
      "0.3754997414667962 0.6877498707333981 1.0\n",
      "-0.21159754999200908 0.39420122500399546 0.0\n",
      "0.37895952961418405 0.689479764807092 1.0\n",
      "-0.10621235658603279 0.4468938217069836 0.0\n",
      "0.1994647903862029 0.5997323951931015 1.0\n",
      "0.43416066145877485 0.7170803307293874 1.0\n",
      "-0.19983779925271805 0.400081100373641 0.0\n",
      "-0.18869371993060657 0.4056531400346967 0.0\n",
      "-0.22452436164375822 0.3877378191781209 0.0\n",
      "0.22406585483496866 0.6120329274174843 1.0\n",
      "-0.13097240009656919 0.4345137999517154 0.0\n",
      "0.34047786380994405 0.670238931904972 1.0\n",
      "-0.20514528591848186 0.39742735704075904 0.0\n",
      "0.3850373181446307 0.6925186590723154 1.0\n",
      "0.468399197977759 0.7341995989888794 1.0\n",
      "-0.19189902876873255 0.4040504856156337 0.0\n",
      "-0.17469652815167946 0.41265173592416027 0.0\n",
      "0.3086621256504956 0.6543310628252478 1.0\n",
      "0.29875348648003935 0.6493767432400197 1.0\n",
      "0.46172093095959643 0.7308604654797982 1.0\n",
      "0.001022375250360641 0.5005111876251803 1.0\n",
      "0.3654099344676872 0.6827049672338437 1.0\n",
      "-0.15060451338834824 0.4246977433058259 0.0\n",
      "0.3947973939194319 0.6973986969597159 1.0\n",
      "0.24954216337107543 0.6247710816855377 1.0\n",
      "Running Accuracy: 100.0%\n",
      "EPOCH LOSS:59.17025583127734\n",
      "******EPOCH #11 END ******\n",
      "******EPOCH #12 START ******\n",
      "0.27379682849731846 0.6368984142486592 1.0\n",
      "0.2271886801721632 0.6135943400860816 1.0\n",
      "-0.2584216510526919 0.37078917447365406 0.0\n",
      "-0.25846017386017195 0.370769913069914 0.0\n",
      "0.4409149128512838 0.7204574564256419 1.0\n",
      "0.27432480263783143 0.6371624013189157 1.0\n",
      "0.47917151784463563 0.7395857589223178 1.0\n",
      "0.20727074512771726 0.6036353725638586 1.0\n",
      "-0.1607655347974738 0.4196172326012631 0.0\n",
      "-0.22309229860503277 0.3884538506974836 0.0\n",
      "0.38186691956154195 0.690933459780771 1.0\n",
      "-0.06902662985591307 0.4654866850720435 0.0\n",
      "-0.17325248623595108 0.4133737568820245 0.0\n",
      "-0.22218836350051274 0.38890581824974363 0.0\n",
      "0.40642234899568497 0.7032111744978424 1.0\n",
      "0.38959017234927235 0.6947950861746361 1.0\n",
      "-0.2322591476725177 0.3838704261637411 0.0\n",
      "0.39632753942021975 0.6981637697101098 1.0\n",
      "-0.11904512285840613 0.4404774385707969 0.0\n",
      "0.20006249765916334 0.6000312488295817 1.0\n",
      "0.44864464483963523 0.7243223224198176 1.0\n",
      "-0.2184605552772826 0.3907697223613587 0.0\n",
      "-0.2024570318131349 0.39877148409343255 0.0\n",
      "-0.24645867166363788 0.37677066416818106 0.0\n",
      "0.22463825096402767 0.6123191254820138 1.0\n",
      "-0.14625100089255494 0.42687449955372253 0.0\n",
      "0.3532759649090851 0.6766379824545425 1.0\n",
      "-0.2258913704977628 0.3870543147511186 0.0\n",
      "0.3967408369922041 0.698370418496102 1.0\n",
      "0.48756018417284974 0.7437800920864248 1.0\n",
      "-0.20712790497537176 0.3964360475123141 0.0\n",
      "-0.19257265306964694 0.4037136734651765 0.0\n",
      "0.32210195389229934 0.6610509769461497 1.0\n",
      "0.30619906541844893 0.6530995327092245 1.0\n",
      "0.48260504827424816 0.741302524137124 1.0\n",
      "-0.005432865878336801 0.4972835670608316 1.0\n",
      "0.3721241082507635 0.6860620541253817 1.0\n",
      "-0.16391681134060954 0.41804159432969523 0.0\n",
      "0.4084848875047479 0.704242443752374 1.0\n",
      "0.25161444546914624 0.6258072227345731 1.0\n",
      "Running Accuracy: 97.5%\n",
      "EPOCH LOSS:57.28567997339701\n",
      "******EPOCH #12 END ******\n",
      "******EPOCH #13 START ******\n",
      "0.2760344905435322 0.6380172452717661 1.0\n",
      "0.23193720419209723 0.6159686020960486 1.0\n",
      "-0.2780597822045433 0.36097010889772835 0.0\n",
      "-0.2783396607101339 0.3608301696449331 0.0\n",
      "0.45420100638153793 0.7271005031907689 1.0\n",
      "0.279039810378935 0.6395199051894676 1.0\n",
      "0.49775469385644266 0.7488773469282213 1.0\n",
      "0.20960905395008683 0.6048045269750434 1.0\n",
      "-0.18185423150495372 0.40907288424752314 0.0\n",
      "-0.24633049193177925 0.3768347540341104 0.0\n",
      "0.3894506566528768 0.6947253283264384 1.0\n",
      "-0.07801670239131558 0.4609916488043422 0.0\n",
      "-0.18746809597452063 0.4062659520127397 0.0\n",
      "-0.23652900288286172 0.38173549855856914 0.0\n",
      "0.42043710753616775 0.7102185537680838 1.0\n",
      "0.40371008350181914 0.7018550417509095 1.0\n",
      "-0.25212141949663436 0.3739392902516828 0.0\n",
      "0.4119987121038015 0.7059993560519008 1.0\n",
      "-0.13292684947611177 0.4335365752619441 0.0\n",
      "0.20099176509063266 0.6004958825453164 1.0\n",
      "0.46225941823054173 0.7311297091152709 1.0\n",
      "-0.23733531996715718 0.3813323400164214 0.0\n",
      "-0.21559514935559182 0.39220242532220406 0.0\n",
      "-0.26814567257186595 0.365927163714067 0.0\n",
      "0.22521100414965278 0.6126055020748264 1.0\n",
      "-0.16102124059940354 0.4194893797002982 0.0\n",
      "0.3651847710149154 0.6825923855074577 1.0\n",
      "-0.24662178189757877 0.3766891090512106 0.0\n",
      "0.40785975787458256 0.7039298789372913 1.0\n",
      "0.5054259622742128 0.7527129811371064 1.0\n",
      "-0.2218931979987936 0.3890534010006032 0.0\n",
      "-0.21013725472504213 0.3949313726374789 0.0\n",
      "0.33441949019013817 0.6672097450950691 1.0\n",
      "0.3125610792210618 0.6562805396105309 1.0\n",
      "0.5018814154883181 0.750940707744159 1.0\n",
      "-0.011491315082388487 0.49425434245880573 1.0\n",
      "0.37674539296093706 0.6883726964804685 1.0\n",
      "-0.17821762838498179 0.4108911858075091 0.0\n",
      "0.4213874039706532 0.7106937019853266 1.0\n",
      "0.2539865191873923 0.6269932595936961 1.0\n",
      "Running Accuracy: 97.5%\n",
      "EPOCH LOSS:55.5173634444409\n",
      "******EPOCH #13 END ******\n",
      "******EPOCH #14 START ******\n",
      "0.27827744286449757 0.6391387214322488 1.0\n",
      "0.2371136441087679 0.618556822054384 1.0\n",
      "-0.2968432443352008 0.3515783778323996 0.0\n",
      "-0.29742077332902667 0.3512896133354867 0.0\n",
      "0.4670147495593115 0.7335073747796558 1.0\n",
      "0.28411186090318785 0.6420559304515939 1.0\n",
      "0.51541191929682 0.7577059596484099 1.0\n",
      "0.21168305676918414 0.605841528384592 1.0\n",
      "-0.20337397736487778 0.39831301131756114 0.0\n",
      "-0.26887633076937023 0.3655618346153149 0.0\n",
      "0.3964771124974449 0.6982385562487224 1.0\n",
      "-0.08768721720002126 0.45615639139998937 0.0\n",
      "-0.20096504176765773 0.39951747911617114 0.0\n",
      "-0.24956591519581905 0.3752170424020905 0.0\n",
      "0.43446960794802514 0.7172348039740126 1.0\n",
      "0.4178953505353441 0.708947675267672 1.0\n",
      "-0.2714320782721703 0.36428396086391485 0.0\n",
      "0.4261352582569645 0.7130676291284823 1.0\n",
      "-0.14803731166926687 0.4259813441653666 0.0\n",
      "0.20231824552730548 0.6011591227636528 1.0\n",
      "0.47529527050547904 0.7376476352527395 1.0\n",
      "-0.2567708289966062 0.3716145855016969 0.0\n",
      "-0.22795189957703543 0.3860240502114823 0.0\n",
      "-0.289757700881466 0.355121149559267 0.0\n",
      "0.22622449070983963 0.6131122453549198 1.0\n",
      "-0.17513710135286265 0.4124314493235687 0.0\n",
      "0.376892700302656 0.688446350151328 1.0\n",
      "-0.2673894834521632 0.3663052582739184 0.0\n",
      "0.41915669679871237 0.7095783483993562 1.0\n",
      "0.5222458339850125 0.7611229169925062 1.0\n",
      "-0.2364478637248858 0.3817760681375571 0.0\n",
      "-0.22731020847426298 0.3863448957628685 0.0\n",
      "0.34616962242385646 0.6730848112119282 1.0\n",
      "0.3188418144979626 0.6594209072489813 1.0\n",
      "0.5197702240519633 0.7598851120259816 1.0\n",
      "-0.01733946574054246 0.49133026712972877 1.0\n",
      "0.3810607675977008 0.6905303837988503 1.0\n",
      "-0.1928960505809012 0.4035519747095494 0.0\n",
      "0.4341154893050175 0.7170577446525087 1.0\n",
      "0.25712010145213593 0.628560050726068 1.0\n",
      "Running Accuracy: 97.5%\n",
      "EPOCH LOSS:53.825539309968576\n",
      "******EPOCH #14 END ******\n",
      "******EPOCH #15 START ******\n",
      "0.2815818029343956 0.6407909014671977 1.0\n",
      "0.24221544954159024 0.6211077247707951 1.0\n",
      "-0.3150002966754696 0.3424998516622652 0.0\n",
      "-0.3158291799108354 0.34208541004458226 0.0\n",
      "0.479887100547047 0.7399435502735234 1.0\n",
      "0.2902517914810791 0.6451258957405396 1.0\n",
      "0.5321807145331373 0.7660903572665687 1.0\n",
      "0.21435558751273898 0.6071777937563695 1.0\n",
      "-0.22527580046958284 0.3873620997652086 0.0\n",
      "-0.2909139858127684 0.3545430070936158 0.0\n",
      "0.40332578042929046 0.7016628902146452 1.0\n",
      "-0.09777722109691495 0.4511113894515425 0.0\n",
      "-0.21405838025154833 0.39297080987422583 0.0\n",
      "-0.2616008445253065 0.36919957773734674 0.0\n",
      "0.4491364876543761 0.7245682438271881 1.0\n",
      "0.4323623914030095 0.7161811957015047 1.0\n",
      "-0.29020472544287823 0.3548976372785609 0.0\n",
      "0.43960123843828036 0.7198006192191402 1.0\n",
      "-0.1643087415355009 0.41784562923224955 0.0\n",
      "0.2041137348176434 0.6020568674088217 1.0\n",
      "0.4883287998800516 0.7441643999400258 1.0\n",
      "-0.2766781630294229 0.3616609184852886 0.0\n",
      "-0.23936967262503905 0.3803151636874805 0.0\n",
      "-0.31125431796485614 0.34437284101757193 0.0\n",
      "0.22822805029164872 0.6141140251458244 1.0\n",
      "-0.1884993251171697 0.40575033744141514 0.0\n",
      "0.38936131783614025 0.6946806589180701 1.0\n",
      "-0.28798008736054864 0.35600995631972565 0.0\n",
      "0.4316026909945164 0.7158013454972583 1.0\n",
      "0.5388249446972316 0.7694124723486158 1.0\n",
      "-0.2507154505789595 0.37464227471052025 0.0\n",
      "-0.24382703471713996 0.37808648264143 0.0\n",
      "0.3582751925939722 0.6791375962969861 1.0\n",
      "0.3263134581081788 0.6631567290540894 1.0\n",
      "0.5371070650573682 0.7685535325286841 1.0\n",
      "-0.02268728679900739 0.48865635660049633 1.0\n",
      "0.3869488610089322 0.6934744305044661 1.0\n",
      "-0.2068489223305896 0.3965755388347052 0.0\n",
      "0.4474672872645514 0.7237336436322757 1.0\n",
      "0.26148130054036717 0.6307406502701836 1.0\n",
      "Running Accuracy: 97.5%\n",
      "EPOCH LOSS:52.15886645832423\n",
      "******EPOCH #15 END ******\n",
      "******EPOCH #16 START ******\n",
      "0.2868313985813709 0.6434156992906854 1.0\n",
      "0.2469497485426133 0.6234748742713067 1.0\n",
      "-0.3324943514970743 0.33375282425146285 0.0\n",
      "-0.3334539433638949 0.33327302831805256 0.0\n",
      "0.49353434253540535 0.7467671712677026 1.0\n",
      "0.29807091198399355 0.6490354559919967 1.0\n",
      "0.5485825143624434 0.7742912571812217 1.0\n",
      "0.21855056466827694 0.6092752823341385 1.0\n",
      "-0.24718914218046617 0.3764054289097669 0.0\n",
      "-0.31227113117752603 0.343864434411237 0.0\n",
      "0.4104816624555865 0.7052408312277932 1.0\n",
      "-0.10785989857986739 0.44607005071006633 0.0\n",
      "-0.22696051029937675 0.3865197448503116 0.0\n",
      "-0.27268120647226385 0.36365939676386805 0.0\n",
      "0.4651365470959992 0.7325682735479996 1.0\n",
      "0.44745870478362665 0.7237293523918134 1.0\n",
      "-0.3080093063854873 0.34599534680725635 0.0\n",
      "0.4535686726828922 0.7267843363414461 1.0\n",
      "-0.1812160692302971 0.40939196538485145 0.0\n",
      "0.20677342131454313 0.6033867106572716 1.0\n",
      "0.5018987342815553 0.7509493671407776 1.0\n",
      "-0.29659829819082023 0.3517008509045899 0.0\n",
      "-0.24976973865521945 0.3751151306723903 0.0\n",
      "-0.3323031881751166 0.3338484059124417 0.0\n",
      "0.23183031603044513 0.6159151580152226 1.0\n",
      "-0.20114860528413986 0.3994256973579301 0.0\n",
      "0.4032968106669441 0.7016484053334721 1.0\n",
      "-0.30791738322182755 0.3460413083890862 0.0\n",
      "0.4459480067929812 0.7229740033964906 1.0\n",
      "0.5560182046268769 0.7780091023134384 1.0\n",
      "-0.26432141109465623 0.3678392944526719 0.0\n",
      "-0.259299494607768 0.370350252696116 0.0\n",
      "0.3715225336811595 0.6857612668405797 1.0\n",
      "0.33591238137686585 0.6679561906884329 1.0\n",
      "0.5547943532797712 0.7773971766398856 1.0\n",
      "-0.02707684617534134 0.48646157691232933 1.0\n",
      "0.3956211126016631 0.6978105563008316 1.0\n",
      "-0.21889864020274952 0.39055067989862524 0.0\n",
      "0.4620250896445307 0.7310125448222653 1.0\n",
      "0.2675243653407867 0.6337621826703934 1.0\n",
      "Running Accuracy: 97.5%\n",
      "EPOCH LOSS:50.47636778435121\n",
      "******EPOCH #16 END ******\n",
      "******EPOCH #17 START ******\n",
      "0.2941928599192507 0.6470964299596254 1.0\n",
      "0.2510315154127415 0.6255157577063708 1.0\n",
      "-0.34914700526977654 0.32542649736511176 0.0\n",
      "-0.3500729243248162 0.3249635378375919 0.0\n",
      "0.5083893603349358 0.7541946801674679 1.0\n",
      "0.3076204494315006 0.6538102247157502 1.0\n",
      "0.5651395408311595 0.7825697704155797 1.0\n",
      "0.22469876710949305 0.6123493835547466 1.0\n",
      "-0.2685964191585792 0.3657017904207104 0.0\n",
      "-0.3325271924067582 0.3337364037966209 0.0\n",
      "0.4181378526744915 0.7090689263372457 1.0\n",
      "-0.11767967841347271 0.44116016079326364 0.0\n",
      "-0.23978336232738984 0.3801083188363051 0.0\n",
      "-0.28272022786933126 0.35863988606533437 0.0\n",
      "0.4827075914826236 0.7413537957413118 1.0\n",
      "0.46322140202133455 0.7316107010106673 1.0\n",
      "-0.32425174692500996 0.33787412653749505 0.0\n",
      "0.4687717412828929 0.7343858706414464 1.0\n",
      "-0.19809465344897736 0.4009526732755113 0.0\n",
      "0.21088550811458717 0.6054427540572935 1.0\n",
      "0.5160293041325351 0.7580146520662676 1.0\n",
      "-0.3160381429349819 0.34198092853250905 0.0\n",
      "-0.2594458661280957 0.37027706693595214 0.0\n",
      "-0.3524590490669403 0.3237704754665298 0.0\n",
      "0.2374191123615385 0.6187095561807693 1.0\n",
      "-0.21352872947798385 0.3932356352610081 0.0\n",
      "0.4186723490975055 0.7093361745487528 1.0\n",
      "-0.3267475666754759 0.33662621666226206 0.0\n",
      "0.4622654825251393 0.7311327412625697 1.0\n",
      "0.574220287161359 0.7871101435806795 1.0\n",
      "-0.27703128954971434 0.36148435522514283 0.0\n",
      "-0.27358937641497727 0.36320531179251136 0.0\n",
      "0.3860168797641558 0.6930084398820779 1.0\n",
      "0.3476547654082104 0.6738273827041052 1.0\n",
      "0.573238752643558 0.786619376321779 1.0\n",
      "-0.030286357481699944 0.48485682125915003 1.0\n",
      "0.4071465626914565 0.7035732813457283 1.0\n",
      "-0.2282505824120813 0.38587470879395935 0.0\n",
      "0.4776734531931141 0.7388367265965571 1.0\n",
      "0.2754652036678783 0.6377326018339391 1.0\n",
      "Running Accuracy: 97.5%\n",
      "EPOCH LOSS:48.768618881723306\n",
      "******EPOCH #17 END ******\n",
      "******EPOCH #18 START ******\n",
      "0.3028979359078211 0.6514489679539106 1.0\n",
      "0.2539978384589153 0.6269989192294576 1.0\n",
      "-0.3648380161069775 0.31758099194651124 0.0\n",
      "-0.36558256351571317 0.3172087182421434 0.0\n",
      "0.5243625927148468 0.7621812963574234 1.0\n",
      "0.3181444354374111 0.6590722177187056 1.0\n",
      "0.5820424830697452 0.7910212415348725 1.0\n",
      "0.23251548534628547 0.6162577426731427 1.0\n",
      "-0.2890980575614708 0.3554509712192646 0.0\n",
      "-0.35124651790239325 0.3243767410488034 0.0\n",
      "0.42599047692087744 0.7129952384604388 1.0\n",
      "-0.12739813095188662 0.4363009345240567 0.0\n",
      "-0.2525834645030389 0.37370826774848054 0.0\n",
      "-0.29170564583309344 0.3541471770834533 0.0\n",
      "0.5013317338110507 0.7506658669055253 1.0\n",
      "0.47913711576874907 0.7395685578843745 1.0\n",
      "-0.3385426809333426 0.3307286595333287 0.0\n",
      "0.48513715556653547 0.7425685777832678 1.0\n",
      "-0.2144946017797582 0.3927526991101209 0.0\n",
      "0.21689211308403045 0.6084460565420152 1.0\n",
      "0.5302045511248417 0.7651022755624208 1.0\n",
      "-0.3346737626635111 0.33266311866824444 0.0\n",
      "-0.2691126218591944 0.3654436890704028 0.0\n",
      "-0.3713800748901549 0.31430996255492255 0.0\n",
      "0.24498384064182843 0.6224919203209143 1.0\n",
      "-0.2264414176175631 0.38677929119121846 0.0\n",
      "0.4348162975194325 0.7174081487597163 1.0\n",
      "-0.34426150105238484 0.3278692494738076 0.0\n",
      "0.47997772789927184 0.7399888639496359 1.0\n",
      "0.5933430990805894 0.7966715495402947 1.0\n",
      "-0.28898040807452086 0.35550979596273957 0.0\n",
      "-0.2869946511443641 0.3565026744278179 0.0\n",
      "0.40121046587093745 0.7006052329354687 1.0\n",
      "0.36063042472224915 0.6803152123611246 1.0\n",
      "0.592326209826526 0.7961631049132629 1.0\n",
      "-0.03237226036128643 0.4838138698193568 1.0\n",
      "0.42060760927009705 0.7103038046350485 1.0\n",
      "-0.23479661651643757 0.3826016917417812 0.0\n",
      "0.49364896626908716 0.7468244831345436 1.0\n",
      "0.28515256695769386 0.6425762834788469 1.0\n",
      "Running Accuracy: 97.5%\n",
      "EPOCH LOSS:47.05910116565397\n",
      "******EPOCH #18 END ******\n",
      "******EPOCH #19 START ******\n",
      "0.31159324082417633 0.6557966204120882 1.0\n",
      "0.2554422171145351 0.6277211085572676 1.0\n",
      "-0.3796097460255953 0.31019512698720236 0.0\n",
      "-0.3800985605034373 0.30995071974828137 0.0\n",
      "0.5410649649751246 0.7705324824875623 1.0\n",
      "0.32839067781307074 0.6641953389065354 1.0\n",
      "0.5992462840159674 0.7996231420079837 1.0\n",
      "0.2412537153633995 0.6206268576816998 1.0\n",
      "-0.30854466401863206 0.345727667990684 0.0\n",
      "-0.3682031390627666 0.3158984304686167 0.0\n",
      "0.4335260319702028 0.7167630159851014 1.0\n",
      "-0.13746071906476687 0.43126964046761657 0.0\n",
      "-0.265401790489836 0.367299104755082 0.0\n",
      "-0.29976505256487807 0.35011747371756097 0.0\n",
      "0.5200256089194846 0.7600128044597423 1.0\n",
      "0.4944102033760759 0.7472051016880379 1.0\n",
      "-0.35089419372131087 0.3245529031393446 0.0\n",
      "0.5020456016567869 0.7510228008283935 1.0\n",
      "-0.23023487463100872 0.3848825626844956 0.0\n",
      "0.22486091096140076 0.6124304554807004 1.0\n",
      "0.543754312242409 0.7718771561212046 1.0\n",
      "-0.35239305146693056 0.3238034742665347 0.0\n",
      "-0.2796382966571238 0.3601808516714381 0.0\n",
      "-0.3890084893798277 0.30549575531008616 0.0\n",
      "0.2541439352170057 0.6270719676085028 1.0\n",
      "-0.2406757823545882 0.3796621088227059 0.0\n",
      "0.4509204675483762 0.7254602337741881 1.0\n",
      "-0.36060399895048834 0.31969800052475583 0.0\n",
      "0.49825979503028295 0.7491298975151415 1.0\n",
      "0.6131020389367102 0.8065510194683552 1.0\n",
      "-0.3005895099507537 0.3497052450246232 0.0\n",
      "-0.30014455322723965 0.3499277233863802 0.0\n",
      "0.41639389364647394 0.708196946823237 1.0\n",
      "0.3735278995366197 0.6867639497683098 1.0\n",
      "0.6117530019609567 0.8058765009804784 1.0\n",
      "-0.03339779519192776 0.4833011024040361 1.0\n",
      "0.43468893436732037 0.7173444671836602 1.0\n",
      "-0.23917633397748916 0.3804118330112554 0.0\n",
      "0.5090521385297128 0.7545260692648563 1.0\n",
      "0.29614611262930857 0.6480730563146543 1.0\n",
      "Running Accuracy: 97.5%\n",
      "EPOCH LOSS:45.382903516373034\n",
      "******EPOCH #19 END ******\n"
     ]
    }
   ],
   "source": [
    "layers_classifier = 5\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def quantum_classifier(inputs, params):\n",
    "    qml.AmplitudeEmbedding(features=inputs, wires=range(wires_qcnn-3), normalize=True)\n",
    "    for l in range(layers_classifier):\n",
    "        cnt = 0\n",
    "        for i in range(wires_qcnn - 1):\n",
    "            qml.RY(params[l*36+cnt],wires=i)\n",
    "            qml.RY(params[l*36+cnt+1],wires=i+1)\n",
    "            qml.CNOT(wires=[i,i+1])\n",
    "            qml.CRZ(params[l*36+cnt+2], wires=[i,i+1])\n",
    "            qml.PauliX(wires=i+1)\n",
    "            qml.CRX(params[l*36+cnt+3],wires=[i,i+1])\n",
    "            cnt = cnt + 4\n",
    "        for i in [wires_qcnn - 1]:\n",
    "            qml.RY(params[l*36+cnt],wires=i)\n",
    "            qml.RY(params[l*36+cnt+1],wires=i-(wires_qcnn - 1))\n",
    "            qml.CNOT(wires=[i,i-(wires_qcnn - 1)])\n",
    "            qml.CRZ(params[l*36+cnt+2], wires=[i,i-(wires_qcnn - 1)])\n",
    "            qml.PauliX(wires=i-(wires_qcnn - 1))\n",
    "            qml.CRX(params[l*36+cnt+3],wires=[i,i-(wires_qcnn - 1)])\n",
    "            cnt = cnt + 4\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "weights_quantum_classifier = {\"params\":layers_classifier*36}\n",
    "q_classifier = qml.qnn.TorchLayer(quantum_classifier, weights_quantum_classifier, init_method=torch.nn.init.normal_)\n",
    "\n",
    "optimizer_classifier = torch.optim.Adam(q_classifier.parameters(),lr=0.01)\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    print(\"******EPOCH #\" + str(epoch) + \" START ******\")\n",
    "    epoch_loss = torch.tensor([0], dtype=torch.float64).to(DEVICE)\n",
    "    running_acc = 0\n",
    "    for i in range(x_aux.shape[0]//BATCH_SIZE):\n",
    "        bs_counter = 0\n",
    "        optimizer_classifier.zero_grad()\n",
    "        loss2 = torch.tensor([0], dtype=torch.float64, requires_grad=True).to(DEVICE)\n",
    "        while bs_counter < BATCH_SIZE: \n",
    "            out = (q_classifier(x_aux[i*BATCH_SIZE+bs_counter])+1)/2\n",
    "            # print(out.item(), q_classifier(x_aux[i*BATCH_SIZE+bs_counter]).item()+1)\n",
    "            # temp_loss = torch.tensor([0], dtype=torch.float64, requires_grad=True).to(DEVICE)\n",
    "            # temp_loss = temp_loss + loss_function(out, y[i*BATCH_SIZE+bs_counter])\n",
    "            loss2 = loss2 + loss_function((q_classifier(x_aux[i*BATCH_SIZE+bs_counter])+1)/2, y[i*BATCH_SIZE+bs_counter])\n",
    "            # print(out.item(), y[i*BATCH_SIZE+bs_counter].item())\n",
    "            epoch_loss = epoch_loss + loss2\n",
    "            if loss_function((q_classifier(x_aux[i*BATCH_SIZE+bs_counter])+1)/2, y[i*BATCH_SIZE+bs_counter]).item() < 0.25:\n",
    "                running_acc = running_acc + 1\n",
    "            bs_counter = bs_counter + 1\n",
    "            print(q_classifier(x_aux[i*BATCH_SIZE+bs_counter]).item(), (q_classifier(x_aux[i*BATCH_SIZE+bs_counter]).item()+1)/2, y[i*BATCH_SIZE+bs_counter].item())\n",
    "        loss2 = loss2/BATCH_SIZE\n",
    "        loss2.backward()\n",
    "        optimizer_classifier.step()\n",
    "        if i % 1 == 0 and i != 0:\n",
    "            print(\"Running Accuracy: \" + str(running_acc/((i+1)*BATCH_SIZE)*100) + \"%\")\n",
    "    print(\"EPOCH LOSS:\" + str(epoch_loss.item()))\n",
    "    print(\"******EPOCH #\" + str(epoch) + \" END ******\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in qram.parameters():\n",
    "#     print(param.shape)\n",
    "# print(list(qram.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in range(pred.shape[0]):\n",
    "#     print(pred[j].item(), ground_truth[j].item())\n",
    "# x_test = torch.tensor(x_test).to(DEVICE)\n",
    "# y_test = torch.tensor(y_test,dtype=torch.double).to(DEVICE)\n",
    "\n",
    "# acc = 0\n",
    "# for i in range(x_test.shape[0]):\n",
    "#     temp_loss = 0\n",
    "#     for j in range(4):\n",
    "#         temp_loss = temp_loss + loss_function(pred[j], y_test[i][j])\n",
    "#     if temp_loss.item() < 1:\n",
    "#         acc += 1\n",
    "\n",
    "# print(\"Testing Accuracy: \" + str(acc/x_test.shape[0]*100)) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0d7be43a922baecbfa48cb40f6786081e2158e784387c7c5e6345b107643248"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
